[["index.html", "Advanced Analytics with Tidymodels Welcome", " Advanced Analytics with Tidymodels Prof. Dr. Jan Kirenz 2020-11-05 Welcome This book provides an introduction to advanced analytics with R using the modeling packages called tidymodels to build, evaluate, compare, and tune predictive models. We’ll cover key concepts in statistical learning and machine learning including overfitting, the holdout method, the bias-variance trade-off, ensembling, cross-validation, and feature engineering. This online book is licensed using the Creative Commons Attribution-NonCommercial 2.0 Generic (CC BY-NC 2.0) License. "],["intro.html", "Chapter 1 Build a Model 1.1 Model type 1.2 Model training 1.3 Model predictions 1.4 Model evaluation", " Chapter 1 Build a Model This tutorial is based on Alisson Hill’s excellent tidymodels workshop. In this tutorial you will learn how to specify a model with the tidymodels package. As data, we use 2,930 houses sold in Ames, IA from 2006 to 2010, collected by the Ames Assessor’s Oﬃce. From this dataset, we only select our dependent variable (Sale_Price) and one predictor variable (Gr_Liv_Area). library(tidyverse) ames &lt;- read_csv(&quot;https://raw.githubusercontent.com/kirenz/datasets/master/ames.csv&quot;) ames &lt;- ames %&gt;% select(Sale_Price, Gr_Liv_Area) glimpse(ames) ## Rows: 2,930 ## Columns: 2 ## $ Sale_Price &lt;dbl&gt; 215000, 105000, 172000, 244000, 189900, 195500, 213500, 1… ## $ Gr_Liv_Area &lt;dbl&gt; 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616, 1804… In this first example, we don’t use data splitting. 1.1 Model type Pick an model type: choose from this list Set the engine: choose from this list Set the mode: regression or classification library(tidymodels) lm_spec &lt;- # your model specification linear_reg() %&gt;% # model type set_engine(engine = &quot;lm&quot;) %&gt;% # model engine set_mode(&quot;regression&quot;) # model mode # Show your model specification lm_spec ## Linear Regression Model Specification (regression) ## ## Computational engine: lm 1.2 Model training In the training process, you run an algorithm on data and thereby produce a model. This process is also called model fitting. lm_fit &lt;- # your fitted model fit( lm_spec, # your model specification Sale_Price ~ Gr_Liv_Area, # a Linear Regression formula data = ames # your data ) # Show your fitted model lm_fit ## parsnip model object ## ## Fit time: 4ms ## ## Call: ## stats::lm(formula = Sale_Price ~ Gr_Liv_Area, data = data) ## ## Coefficients: ## (Intercept) Gr_Liv_Area ## 13289.6 111.7 1.3 Model predictions We use our fitted model to make predictions. price_pred &lt;- lm_fit %&gt;% predict(new_data = ames) %&gt;% mutate(price_truth = ames$Sale_Price) head(price_pred) ## # A tibble: 6 x 2 ## .pred price_truth ## &lt;dbl&gt; &lt;dbl&gt; ## 1 198255. 215000 ## 2 113367. 105000 ## 3 161731. 172000 ## 4 248964. 244000 ## 5 195239. 189900 ## 6 192447. 195500 If we would want to make predictions for new houses, we could proceed as follows: # New values (our x variable) new_homes &lt;- tibble(Gr_Liv_Area = c(334, 1126, 1442, 1500, 1743, 5642)) # Prediction for new houses (predict y) lm_fit %&gt;% predict(new_data = new_homes) ## # A tibble: 6 x 1 ## .pred ## &lt;dbl&gt; ## 1 50595. ## 2 139057. ## 3 174352. ## 4 180831. ## 5 207972. ## 6 643467. 1.4 Model evaluation We use the Root Mean Squared Error (RMSE) to evaluate our regression model. Therefore, we use the function \\(rmse(data, truth, estimate)\\). rmse(data = price_pred, truth = price_truth, estimate = .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 56505. "],["process-with-data-splitting.html", "Chapter 2 Process with data splitting 2.1 Data splitting 2.2 Model type 2.3 Model training 2.4 Model predictions 2.5 Model evaluation", " Chapter 2 Process with data splitting The best way to measure a model’s performance at predicting new data is to actually predict new data. This function “splits” data randomly into a single testing and a single training set: initial_split(data, prop = 3/4, strata, breaks). We also use stratified sampling in this example. 2.1 Data splitting set.seed(100) ames_split &lt;- initial_split(ames, strata = Sale_Price, breaks = 4) ames_train &lt;- training(ames_split) ames_test &lt;- testing(ames_split) 2.2 Model type lm_spec_2 &lt;- linear_reg() %&gt;% set_engine(engine = &quot;lm&quot;) %&gt;% set_mode(&quot;regression&quot;) 2.3 Model training lm_fit_2 &lt;- lm_spec_2 %&gt;% fit(Sale_Price ~ Gr_Liv_Area, data = ames_train) # only use training data 2.4 Model predictions price_pred_2 &lt;- lm_fit %&gt;% predict(new_data = ames_test) %&gt;% mutate(price_truth = ames_test$Sale_Price) 2.5 Model evaluation rmse(price_pred_2, truth = price_truth, estimate = .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 59054. "],["import-data.html", "Chapter 3 Import data", " Chapter 3 Import data library(tidyverse) ames &lt;- read_csv(&quot;https://raw.githubusercontent.com/kirenz/datasets/master/ames.csv&quot;) ames &lt;- ames %&gt;% select(Sale_Price, Gr_Liv_Area) glimpse(ames) ## Rows: 2,930 ## Columns: 2 ## $ Sale_Price &lt;dbl&gt; 215000, 105000, 172000, 244000, 189900, 195500, 213500, 1… ## $ Gr_Liv_Area &lt;dbl&gt; 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616, 1804… "],["build-a-model.html", "Chapter 4 Build a model 4.1 Model specification 4.2 Data split", " Chapter 4 Build a model 4.1 Model specification Build the model: library(tidymodels) lm_spec &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) %&gt;% set_mode(mode = &quot;regression&quot;) 4.2 Data split set.seed(100) new_split &lt;- initial_split(ames) new_train &lt;- training(new_split) new_test &lt;- testing(new_split) "],["fit-the-model.html", "Chapter 5 Fit the model", " Chapter 5 Fit the model lm_fit &lt;- lm_spec %&gt;% fit(Sale_Price ~ Gr_Liv_Area , data = new_train) Make predictions and calculate the RMSE for our training data. lm_fit %&gt;% predict(new_train) %&gt;% mutate(truth = new_train$Sale_Price) %&gt;% rmse(truth, .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 57367. "],["evaluate-model.html", "Chapter 6 Evaluate model", " Chapter 6 Evaluate model To further evaluate our simple Linear Regression model, let’s build a validation set. Note that this process is usually used to compare the performance of multiple models and to tune hyperparameters. In this tutorial however, we only want to demonstrate the process and therefore only use one model. We can build a set of k-Fold cross validation sets and use this set of resamples to estimate the performance of our model using the fit_resamples() function. Note that this function does not do any tuning of the model parameters. The function is only used for computing performance metrics across some set of resamples. It will fit our model lm_spec to each resample and evaluate on the heldout set from each resample. It is important to note, that the function does not even keep the models it trains. First of all, we build a set of 10 validation folds with the function vfold_cv (we also use stratified sampling in this example): set.seed(100) cv_folds &lt;- vfold_cv(new_train, v = 10, strata = Sale_Price, breaks = 4) cv_folds ## # 10-fold cross-validation using stratification ## # A tibble: 10 x 2 ## splits id ## &lt;list&gt; &lt;chr&gt; ## 1 &lt;split [2K/221]&gt; Fold01 ## 2 &lt;split [2K/221]&gt; Fold02 ## 3 &lt;split [2K/220]&gt; Fold03 ## 4 &lt;split [2K/220]&gt; Fold04 ## 5 &lt;split [2K/220]&gt; Fold05 ## 6 &lt;split [2K/220]&gt; Fold06 ## 7 &lt;split [2K/220]&gt; Fold07 ## 8 &lt;split [2K/219]&gt; Fold08 ## 9 &lt;split [2K/219]&gt; Fold09 ## 10 &lt;split [2K/218]&gt; Fold10 Next, let’s fit the model on each of the 10 folds with fit_resamples() and store the results as lm_res: lm_res &lt;- lm_spec %&gt;% fit_resamples( Sale_Price ~ Gr_Liv_Area, resamples = cv_folds ) Now we can collect the performance metrics with collect_metrics(). The metrics show the average performance across all folds. lm_res %&gt;% collect_metrics() ## # A tibble: 2 x 5 ## .metric .estimator mean n std_err ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 rmse standard 57177. 10 1919. ## 2 rsq standard 0.482 10 0.0321 If we would be interested in the results of every split, we could use the option summarize = FALSE: lm_res %&gt;% collect_metrics(summarize = FALSE) ## # A tibble: 20 x 4 ## id .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Fold01 rmse standard 53973. ## 2 Fold01 rsq standard 0.552 ## 3 Fold02 rmse standard 63213. ## 4 Fold02 rsq standard 0.269 ## 5 Fold03 rmse standard 61189. ## 6 Fold03 rsq standard 0.431 ## 7 Fold04 rmse standard 50946. ## 8 Fold04 rsq standard 0.540 ## 9 Fold05 rmse standard 55356. ## 10 Fold05 rsq standard 0.550 ## 11 Fold06 rmse standard 56952. ## 12 Fold06 rsq standard 0.531 ## 13 Fold07 rmse standard 67903. ## 14 Fold07 rsq standard 0.342 ## 15 Fold08 rmse standard 54457. ## 16 Fold08 rsq standard 0.522 ## 17 Fold09 rmse standard 47476. ## 18 Fold09 rsq standard 0.565 ## 19 Fold10 rmse standard 60309. ## 20 Fold10 rsq standard 0.518 "],["evaluate-final-model.html", "Chapter 7 Evaluate final model", " Chapter 7 Evaluate final model Finally, let’s use our testing data and see how we can expect this model to perform on new data. lm_fit %&gt;% predict(new_test) %&gt;% mutate(truth = new_test$Sale_Price) %&gt;% rmse(truth, .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 53885. In this tutorial, we’ll explore a tidymodels package, recipes, which is designed to help you preprocess your data before training your model. Recipes are built as a series of preprocessing steps, such as: converting qualitative predictors to indicator variables (also known as dummy variables), transforming data to be on a different scale (e.g., taking the logarithm of a variable), transforming whole groups of predictors together, extracting key features from raw variables (e.g., getting the day of the week out of a date variable), and so on. If you are familiar with R’s formula interface, a lot of this might sound familiar and like what a formula already does. Recipes can be used to do many of the same things, but they have a much wider range of possibilities. This article shows how to use recipes for modeling. In summary, the idea of the recipes package is to define a recipe or blueprint that can be used to sequentially define the encodings and preprocessing of the data (i.e. “feature engineering”) before we build our models. "],["data-preparation.html", "Chapter 8 Data preparation", " Chapter 8 Data preparation Import data and split the data into training and testing sets using initial_split() library(tidyverse) library(tidymodels) ames &lt;- read_csv(&quot;https://raw.githubusercontent.com/kirenz/datasets/master/ames.csv&quot;) ames &lt;- ames %&gt;% select(-matches(&quot;Qu&quot;)) set.seed(100) new_split &lt;- initial_split(ames) new_train &lt;- training(new_split) new_test &lt;- testing(new_split) "],["recipe.html", "Chapter 9 Recipe 9.1 recipe() 9.2 prep() 9.3 juice() 9.4 bake()", " Chapter 9 Recipe Next, we use a recipe() to build a set of steps for data preprocessing and feature engineering. First, we must tell the recipe() what our model is going to be (using a formula here) and what our training data is. step_novel() will convert all nominal variables to factors. We then convert the factor columns into (one or more) numeric binary (0 and 1) variables for the levels of the training data. We remove any numeric variables that have zero variance. We normalize (center and scale) the numeric variables. 9.1 recipe() ames_rec &lt;- recipe(Sale_Price ~ ., data = new_train) %&gt;% step_novel(all_nominal(), -all_outcomes()) %&gt;% step_dummy(all_nominal()) %&gt;% step_zv(all_predictors()) %&gt;% step_normalize(all_predictors()) # Show the content of our recipe ames_rec ## Data Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 73 ## ## Operations: ## ## Novel factor level assignment for all_nominal(), -all_outcomes() ## Dummy variables from all_nominal() ## Zero variance filter on all_predictors() ## Centering and scaling for all_predictors() 9.2 prep() Finally, we prep() the recipe(). This means we actually do something with the steps and our training data. ames_prep &lt;- prep(ames_rec) Print a summary of our prepped recipe: summary(ames_prep) ## # A tibble: 269 x 4 ## variable type role source ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Lot_Frontage numeric predictor original ## 2 Lot_Area numeric predictor original ## 3 Year_Built numeric predictor original ## 4 Year_Remod_Add numeric predictor original ## 5 Mas_Vnr_Area numeric predictor original ## 6 BsmtFin_SF_1 numeric predictor original ## 7 BsmtFin_SF_2 numeric predictor original ## 8 Bsmt_Unf_SF numeric predictor original ## 9 Total_Bsmt_SF numeric predictor original ## 10 First_Flr_SF numeric predictor original ## # … with 259 more rows 9.3 juice() To obtain the Dataframe from the prepped recipe, we use the function juice(). When we juice() the recipe, we squeeze that training data back out, transformed in the ways we specified: juice(ames_prep) ## # A tibble: 2,198 x 269 ## Lot_Frontage Lot_Area Year_Built Year_Remod_Add Mas_Vnr_Area BsmtFin_SF_1 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.693 0.582 -0.442 -1.26 0.0310 -1.44 ## 2 0.484 0.521 0.849 0.651 -0.570 -0.540 ## 3 0.603 -0.0104 0.882 0.651 -0.459 -0.540 ## 4 -0.498 -0.708 0.982 0.795 -0.570 -0.540 ## 5 -0.439 -0.697 0.684 0.364 -0.570 -1.44 ## 6 -0.558 -0.644 0.783 0.555 -0.570 -0.540 ## 7 0.0674 -0.352 0.915 0.699 -0.570 1.26 ## 8 -1.72 -0.286 0.684 1.08 -0.570 -1.44 ## 9 0.157 -0.228 0.882 0.651 -0.570 1.26 ## 10 0.812 0.0170 0.617 0.268 -0.570 -0.540 ## # … with 2,188 more rows, and 263 more variables: BsmtFin_SF_2 &lt;dbl&gt;, ## # Bsmt_Unf_SF &lt;dbl&gt;, Total_Bsmt_SF &lt;dbl&gt;, First_Flr_SF &lt;dbl&gt;, ## # Second_Flr_SF &lt;dbl&gt;, Gr_Liv_Area &lt;dbl&gt;, Bsmt_Full_Bath &lt;dbl&gt;, ## # Bsmt_Half_Bath &lt;dbl&gt;, Full_Bath &lt;dbl&gt;, Half_Bath &lt;dbl&gt;, ## # Bedroom_AbvGr &lt;dbl&gt;, Kitchen_AbvGr &lt;dbl&gt;, TotRms_AbvGrd &lt;dbl&gt;, ## # Fireplaces &lt;dbl&gt;, Garage_Cars &lt;dbl&gt;, Garage_Area &lt;dbl&gt;, Wood_Deck_SF &lt;dbl&gt;, ## # Open_Porch_SF &lt;dbl&gt;, Enclosed_Porch &lt;dbl&gt;, Three_season_porch &lt;dbl&gt;, ## # Screen_Porch &lt;dbl&gt;, Pool_Area &lt;dbl&gt;, Misc_Val &lt;dbl&gt;, Mo_Sold &lt;dbl&gt;, ## # Year_Sold &lt;dbl&gt;, Longitude &lt;dbl&gt;, Latitude &lt;dbl&gt;, Sale_Price &lt;dbl&gt;, ## # MS_SubClass_One_and_Half_Story_Finished_All_Ages &lt;dbl&gt;, ## # MS_SubClass_One_and_Half_Story_Unfinished_All_Ages &lt;dbl&gt;, ## # MS_SubClass_One_Story_1945_and_Older &lt;dbl&gt;, ## # MS_SubClass_One_Story_1946_and_Newer_All_Styles &lt;dbl&gt;, ## # MS_SubClass_One_Story_PUD_1946_and_Newer &lt;dbl&gt;, ## # MS_SubClass_One_Story_with_Finished_Attic_All_Ages &lt;dbl&gt;, ## # MS_SubClass_PUD_Multilevel_Split_Level_Foyer &lt;dbl&gt;, ## # MS_SubClass_Split_Foyer &lt;dbl&gt;, MS_SubClass_Split_or_Multilevel &lt;dbl&gt;, ## # MS_SubClass_Two_and_Half_Story_All_Ages &lt;dbl&gt;, ## # MS_SubClass_Two_Family_conversion_All_Styles_and_Ages &lt;dbl&gt;, ## # MS_SubClass_Two_Story_1945_and_Older &lt;dbl&gt;, ## # MS_SubClass_Two_Story_1946_and_Newer &lt;dbl&gt;, ## # MS_SubClass_Two_Story_PUD_1946_and_Newer &lt;dbl&gt;, MS_Zoning_C_all &lt;dbl&gt;, ## # MS_Zoning_Floating_Village_Residential &lt;dbl&gt;, ## # MS_Zoning_Residential_High_Density &lt;dbl&gt;, ## # MS_Zoning_Residential_Low_Density &lt;dbl&gt;, ## # MS_Zoning_Residential_Medium_Density &lt;dbl&gt;, Street_Pave &lt;dbl&gt;, ## # Alley_No_Alley_Access &lt;dbl&gt;, Alley_Paved &lt;dbl&gt;, ## # Lot_Shape_Moderately_Irregular &lt;dbl&gt;, Lot_Shape_Regular &lt;dbl&gt;, ## # Lot_Shape_Slightly_Irregular &lt;dbl&gt;, Land_Contour_HLS &lt;dbl&gt;, ## # Land_Contour_Low &lt;dbl&gt;, Land_Contour_Lvl &lt;dbl&gt;, Utilities_NoSeWa &lt;dbl&gt;, ## # Utilities_NoSewr &lt;dbl&gt;, Lot_Config_CulDSac &lt;dbl&gt;, Lot_Config_FR2 &lt;dbl&gt;, ## # Lot_Config_FR3 &lt;dbl&gt;, Lot_Config_Inside &lt;dbl&gt;, Land_Slope_Mod &lt;dbl&gt;, ## # Land_Slope_Sev &lt;dbl&gt;, Neighborhood_Blueste &lt;dbl&gt;, ## # Neighborhood_Briardale &lt;dbl&gt;, Neighborhood_Brookside &lt;dbl&gt;, ## # Neighborhood_Clear_Creek &lt;dbl&gt;, Neighborhood_College_Creek &lt;dbl&gt;, ## # Neighborhood_Crawford &lt;dbl&gt;, Neighborhood_Edwards &lt;dbl&gt;, ## # Neighborhood_Gilbert &lt;dbl&gt;, Neighborhood_Green_Hills &lt;dbl&gt;, ## # Neighborhood_Greens &lt;dbl&gt;, Neighborhood_Iowa_DOT_and_Rail_Road &lt;dbl&gt;, ## # Neighborhood_Landmark &lt;dbl&gt;, Neighborhood_Meadow_Village &lt;dbl&gt;, ## # Neighborhood_Mitchell &lt;dbl&gt;, Neighborhood_North_Ames &lt;dbl&gt;, ## # Neighborhood_Northpark_Villa &lt;dbl&gt;, Neighborhood_Northridge &lt;dbl&gt;, ## # Neighborhood_Northridge_Heights &lt;dbl&gt;, Neighborhood_Northwest_Ames &lt;dbl&gt;, ## # Neighborhood_Old_Town &lt;dbl&gt;, Neighborhood_Sawyer &lt;dbl&gt;, ## # Neighborhood_Sawyer_West &lt;dbl&gt;, Neighborhood_Somerset &lt;dbl&gt;, ## # Neighborhood_South_and_West_of_Iowa_State_University &lt;dbl&gt;, ## # Neighborhood_Stone_Brook &lt;dbl&gt;, Neighborhood_Timberland &lt;dbl&gt;, ## # Neighborhood_Veenker &lt;dbl&gt;, Condition_1_Feedr &lt;dbl&gt;, ## # Condition_1_Norm &lt;dbl&gt;, Condition_1_PosA &lt;dbl&gt;, Condition_1_PosN &lt;dbl&gt;, ## # Condition_1_RRAe &lt;dbl&gt;, Condition_1_RRAn &lt;dbl&gt;, Condition_1_RRNe &lt;dbl&gt;, ## # Condition_1_RRNn &lt;dbl&gt;, Condition_2_Feedr &lt;dbl&gt;, … The prepped recipe ames_prep contains all our transformations for data preprocessing and feature engineering, as well as the data these transformations were estimated from. 9.4 bake() We now can simply apply all of the recipe transformations to the testing data. The function to perform this is called bake(): test_trans &lt;- bake(ames_prep, new_data = new_test) Now it’s time to specify and then fit our models. "],["model-building.html", "Chapter 10 Model building 10.1 Specify model 10.2 Fit model 10.3 Evaluate model 10.4 Evaluate final model", " Chapter 10 Model building 10.1 Specify model lm_spec &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) %&gt;% set_mode(mode = &quot;regression&quot;) 10.2 Fit model lm_fit &lt;- lm_spec %&gt;% fit(Sale_Price ~ . , data = juice(ames_prep)) 10.3 Evaluate model set.seed(100) cv_folds &lt;- vfold_cv(juice(ames_prep), v = 10, strata = Sale_Price, breaks = 4) lm_res &lt;- lm_spec %&gt;% fit_resamples( Sale_Price ~ ., resamples = cv_folds ) lm_res %&gt;% collect_metrics() ## # A tibble: 2 x 5 ## .metric .estimator mean n std_err ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 rmse standard 44256. 10 5215. ## 2 rsq standard 0.723 10 0.0534 10.4 Evaluate final model Finally, let’s use our testing data and see how we can expect this model to perform on new data. lm_fit %&gt;% predict(test_trans) %&gt;% mutate(truth = test_trans$Sale_Price) %&gt;% rmse(truth, .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 26187. "],["components-of-our-recipe.html", "Chapter 11 Components of our recipe 11.1 recipe() 11.2 Helper functions 11.3 step_novel() 11.4 step_dummy() 11.5 step_zv() 11.6 step_normalize()", " Chapter 11 Components of our recipe Let’s have a closer look at the different components of the recipe. 11.1 recipe() First of all, we created a simple recipe (we call it rec) containing only an outcome (Sale_Price) and predictors (all other variables in the dataset: .). To demonstrate the use of recipes step by step, we create a new object with the name rec: rec &lt;- recipe(Sale_Price ~ ., data = ames) The formula Sale_Price ~ . indicates outcomes vs predictors. 11.2 Helper functions Here some helper functions for selecting sets of variables: all_predictors(): Each x variable (right side of ~) all_outcomes(): Each y variable (left side of ~) all_numeric(): Each numeric variable all_nominal(): Each categorical variable (e.g. factor, string) dplyr::select() helpers starts_with(‘Lot_’), etc. 11.3 step_novel() step_novel() will convert all nominal variables to factors. It adds a catch-all level to a factor for any new values, which lets R intelligently predict new levels in the test set. Missing values will remain missing. rec %&gt;% step_novel(all_nominal(), -all_outcomes()) ## Data Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 73 ## ## Operations: ## ## Novel factor level assignment for all_nominal(), -all_outcomes() 11.4 step_dummy() Converts nominal data into dummy variables. rec %&gt;% step_dummy(all_nominal()) ## Data Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 73 ## ## Operations: ## ## Dummy variables from all_nominal() 11.5 step_zv() step_zv() removes zero variance variables (variables that contain only a single value). rec %&gt;% step_zv(all_predictors()) ## Data Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 73 ## ## Operations: ## ## Zero variance filter on all_predictors() When the recipe is applied to the data set, a column could contain only zeros. This is a “zero-variance predictor” that has no information within the column. While some R functions will not produce an error for such predictors, it usually causes warnings and other issues. step_zv() will remove columns from the data when the training set data have a single value- This step should be added to the recipe after step_dummy(). 11.6 step_normalize() Centers then scales numeric variable (mean = 0, sd = 1) rec %&gt;% step_normalize(all_numeric()) ## Data Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 73 ## ## Operations: ## ## Centering and scaling for all_numeric() "],["workflows.html", "Chapter 12 Workflows 12.1 workflow() 12.2 fit() 12.3 predict() &amp; rmse()", " Chapter 12 Workflows To combine the data preparation with the model building, we could use the package workflows. A workflow is an object that can bundle together your pre-processing, modeling, and post-processing requests: 12.1 workflow() new_wf &lt;- workflow() %&gt;% add_recipe(ames_rec) %&gt;% add_model(lm_spec) 12.2 fit() new_wf_fit &lt;- new_wf %&gt;% fit(data = new_train) 12.3 predict() &amp; rmse() Make predictions and calculate the RMSE for our training data. new_wf_fit %&gt;% predict(new_train) %&gt;% mutate(truth = new_train$Sale_Price) %&gt;% rmse(truth, .pred) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 22424. In this tutorial, we’ll explore the tidymodels packages recipes and workflows which are designed to help you preprocess your data before training your model. Recipes are built as a series of preprocessing steps, such as: converting qualitative predictors to indicator variables (also known as dummy variables), transforming data to be on a different scale (e.g., taking the logarithm of a variable), transforming whole groups of predictors together, extracting key features from raw variables (e.g., getting the day of the week out of a date variable), and so on. If you are familiar with R’s formula interface, a lot of this might sound familiar and like what a formula already does. Recipes can be used to do many of the same things, but they have a much wider range of possibilities. This article shows how to use recipes for modeling. To combine all of the steps discussed above with model building, we can use the package workflows. A workflow is an object that can bundle together your pre-processing, modeling, and post-processing requests. To use the code in this tutorial, you will need to install the following packages: nycflights13, skimr, and tidymodels. library(tidymodels) # for flight data: library(nycflights13) # for variable summaries: library(skimr) "],["data-preparation-1.html", "Chapter 13 Data preparation 13.1 Data overview", " Chapter 13 Data preparation Let’s use the nycflights13 data to predict whether a plane arrives more than 30 minutes late. This data set contains information on 325,819 flights departing near New York City in 2013. Furthermore, it contains weather data (hourly meterological data for LGA, JFK and EWR). Let’s start by loading the data and making a few changes to the variables: flight_data_all &lt;- flights %&gt;% mutate( # Convert the arrival delay to a factor arr_delay = ifelse(arr_delay &gt;= 30, &quot;late&quot;, &quot;on_time&quot;), arr_delay = factor(arr_delay), # We will use the date (not date-time) # in the recipe below date = as.Date(time_hour) ) %&gt;% # Include weather data inner_join(weather, by = c(&quot;origin&quot;, &quot;time_hour&quot;)) %&gt;% # Only retain the specific columns we will use select(dep_time, flight, origin, dest, air_time, distance, carrier, date, arr_delay, time_hour) %&gt;% # Exclude missing data na.omit() %&gt;% # For creating models, it is # better to have qualitative columns # encoded as factors (instead of character strings) mutate(across(where(is.character), as.factor)) To speed up later calculations we only use a sample of the data: set.seed(123) flight_data &lt;- sample_n(flight_data_all, 10000) We can see that around 16% of the flights in this data set arrived more than 30 minutes late: flight_data %&gt;% count(arr_delay) %&gt;% mutate(prop = n/sum(n)) ## # A tibble: 2 x 3 ## arr_delay n prop ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 late 1589 0.159 ## 2 on_time 8411 0.841 13.1 Data overview Before we start building up our recipe, let’s take a quick look at a few specific variables that will be important for both preprocessing and modeling. First, notice that the variable we created called arr_delay is a factor variable; it is important that our outcome variable for training a classification model (at least a logistic regression model) is numeric. glimpse(flight_data) ## Rows: 10,000 ## Columns: 10 ## $ dep_time &lt;int&gt; 825, 657, 1835, 1827, 1600, 1039, 1142, 1723, 1446, 2140, 2… ## $ flight &lt;int&gt; 120, 4122, 4517, 373, 4502, 4589, 4646, 4195, 3588, 3660, 1… ## $ origin &lt;fct&gt; JFK, EWR, LGA, JFK, EWR, LGA, LGA, EWR, LGA, LGA, JFK, EWR,… ## $ dest &lt;fct&gt; LAX, SDF, CRW, CLT, BNA, DTW, MSP, BNA, MSP, BNA, LAX, DCA,… ## $ air_time &lt;dbl&gt; 316, 104, 75, 90, 119, 93, 139, 130, 138, 104, 323, 36, 126… ## $ distance &lt;dbl&gt; 2475, 642, 444, 541, 748, 502, 1020, 748, 1020, 764, 2475, … ## $ carrier &lt;fct&gt; DL, EV, MQ, US, EV, MQ, MQ, EV, MQ, MQ, AA, EV, EV, EV, EV,… ## $ date &lt;date&gt; 2013-05-03, 2013-03-04, 2013-02-20, 2013-04-02, 2013-06-13… ## $ arr_delay &lt;fct&gt; on_time, on_time, on_time, on_time, late, on_time, on_time,… ## $ time_hour &lt;dttm&gt; 2013-05-03 08:00:00, 2013-03-04 07:00:00, 2013-02-20 18:00… Second, there are two variables that we don’t want to use as predictors in our model, but that we would like to retain as identification variables that can be used to troubleshoot poorly predicted data points. These are flight, a numeric value, and time_hour, a date-time value. Third, there are 79 flight destinations contained in dest and 14 distinct carriers. flight_data %&gt;% skimr::skim(dest, carrier) Table 13.1: Data summary Name Piped data Number of rows 10000 Number of columns 10 _______________________ Column type frequency: factor 2 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts dest 0 1 FALSE 97 ATL: 523, LAX: 506, BOS: 496, ORD: 482 carrier 0 1 FALSE 15 UA: 1757, EV: 1598, B6: 1589, DL: 1435 Because we’ll be using a logistic regression model in this tutorial, the variables dest and carrier will be converted to dummy variables. However, some of these values do not occur very frequently and this could complicate our analysis. We’ll discuss specific steps later in this tutorial that we can add to our recipe to address this issue before modeling. "],["data-splitting-1.html", "Chapter 14 Data splitting", " Chapter 14 Data splitting To get started, let’s split this single dataset into two: a training set and a testing set. We’ll keep most of the rows in the original dataset (subset chosen randomly) in the training set. The training data will be used to fit the model, and the testing set will be used to measure model performance. To do this, we can use the rsample package (included in tidymodels) to create an object that contains the information on how to split the data, and then two more rsample functions to create data frames for the training and testing sets: # Fix the random numbers by setting the seed # This enables the analysis to be reproducible # when random numbers are used set.seed(555) # Put 3/4 of the data into the training set data_split &lt;- initial_split(flight_data, prop = 3/4) # Create data frames for the two sets: train_data &lt;- training(data_split) test_data &lt;- testing(data_split) "],["create-recipe-and-roles.html", "Chapter 15 Create recipe and roles 15.1 Create features", " Chapter 15 Create recipe and roles To get started, let’s create a recipe for a classification model. Before training the models, we can use a recipe to create a few new predictors and conduct some preprocessing required by the model. The recipe() function has two arguments: A formula. Any variable on the left-hand side of the tilde (~) is considered the model outcome (here, arr_delay). On the right-hand side of the tilde are the predictors. Variables may be listed by name, or you can use the dot (.) to indicate all other variables as predictors. The data. A recipe is associated with the data set used to create the model. This will typically be the training set, so data = train_data here. Naming a data set doesn’t actually change the data itself; it is only used to catalog the names of the variables and their types, like factors, integers, dates, etc. We can also add roles to this recipe. We can use the update_role() function to let recipes know that flight and time_hour are variables with a custom role that we call “ID” (a role can have any character value). Whereas our formula included all variables in the training set other than arr_delay as predictors, this tells the recipe to keep these two variables but not use them as either outcomes or predictors. flights_rec &lt;- recipe(arr_delay ~ ., data = train_data) %&gt;% update_role(flight, time_hour, new_role = &quot;ID&quot;) This step of adding roles to a recipe is optional; the purpose of using it here is that those two variables can be retained in the data but not included in the model. This can be convenient when, after the model is fit, we want to investigate some poorly predicted value. These ID columns will be available and can be used to try to understand what went wrong. To get the current set of variables and roles, use the summary() function: summary(flights_rec) ## # A tibble: 10 x 4 ## variable type role source ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 dep_time numeric predictor original ## 2 flight numeric ID original ## 3 origin nominal predictor original ## 4 dest nominal predictor original ## 5 air_time numeric predictor original ## 6 distance numeric predictor original ## 7 carrier nominal predictor original ## 8 date date predictor original ## 9 time_hour date ID original ## 10 arr_delay nominal outcome original 15.1 Create features Now we can start adding steps onto our recipe using the pipe operator. 15.1.1 Date Perhaps it is reasonable for the date of the flight to have an effect on the likelihood of a late arrival. A little bit of feature engineering might go a long way to improving our model. How should the date be encoded into the model? The date column has an R date object so including that column “as is” will mean that the model will convert it to a numeric format equal to the number of days after a reference date: flight_data %&gt;% distinct(date) %&gt;% mutate(numeric_date = as.numeric(date)) ## # A tibble: 364 x 2 ## date numeric_date ## &lt;date&gt; &lt;dbl&gt; ## 1 2013-05-03 15828 ## 2 2013-03-04 15768 ## 3 2013-02-20 15756 ## 4 2013-04-02 15797 ## 5 2013-06-13 15869 ## 6 2013-02-21 15757 ## 7 2013-05-08 15833 ## 8 2013-10-21 15999 ## 9 2013-11-12 16021 ## 10 2013-09-12 15960 ## # … with 354 more rows It’s possible that the numeric date variable is a good option for modeling. However, it might be better to add model terms derived from the date that have a better potential to be important to the model. For example, we could derive the following meaningful features from the single date variable: the day of the week, the month, and whether or not the date corresponds to a holiday. Let’s do all three of these by adding steps to our recipe: flights_rec &lt;- recipe(arr_delay ~ ., data = train_data) %&gt;% update_role(flight, time_hour, new_role = &quot;ID&quot;) %&gt;% step_date(date, features = c(&quot;dow&quot;, &quot;month&quot;)) %&gt;% step_holiday(date, holidays = timeDate::listHolidays(&quot;US&quot;)) %&gt;% step_rm(date) What do each of these steps do? With step_date(), we created two new factor columns with the appropriate day of the week (dow) and the month. With step_holiday(), we created a binary variable indicating whether the current date is a holiday or not. The argument value of timeDate::listHolidays(\"US\") uses the timeDate package to list the 17 standard US holidays. With step_rm(), we remove the original date variable since we no longer want it in the model. Next, we’ll turn our attention to the variable types of our predictors. Because we plan to train a classifiaction model, we know that predictors will ultimately need to be numeric, as opposed to factor variables. In other words, there may be a difference in how we store our data (in factors inside a data frame), and how the underlying equations require them (a purely numeric matrix). 15.1.2 Dummy variables For factors like dest and origin, standard practice is to convert them into dummy or indicator variables to make them numeric. These are binary values for each level of the factor. For example, our origin variable has values of “EWR”, “JFK”, and “LGA”. The standard dummy variable encoding, shown below, will create two numeric columns of the data that are 1 when the originating airport is “JFK” or “LGA” and zero otherwise, respectively. ORIGIN ORIGIN_JFK ORIGIN_LGA EWR 0 0 JFK 1 0 LGA 0 1 But, unlike the standard model formula methods in R, a recipe does not automatically create these dummy variables for you; you’ll need to tell your recipe to add this step. This is for two reasons. First, many models do not require numeric predictors, so dummy variables may not always be preferred. Second, recipes can also be used for purposes outside of modeling, where non-dummy versions of the variables may work better. For example, you may want to make a table or a plot with a variable as a single factor. For those reasons, you need to explicitly tell recipes to create dummy variables using step_dummy(): flights_rec &lt;- recipe(arr_delay ~ ., data = train_data) %&gt;% update_role(flight, time_hour, new_role = &quot;ID&quot;) %&gt;% step_date(date, features = c(&quot;dow&quot;, &quot;month&quot;)) %&gt;% step_holiday(date, holidays = timeDate::listHolidays(&quot;US&quot;)) %&gt;% step_rm(date) %&gt;% step_dummy(all_nominal(), -all_outcomes()) Here, we did something different than before: instead of applying a step to an individual variable, we used selectors to apply this recipe step to several variables at once. The first selector, all_nominal(), selects all variables that are either factors or characters. The second selector, -all_outcomes() removes any outcome variables from this recipe step. With these two selectors together, our recipe step above translates to: Create dummy variables for all of the factor or character columns unless they are outcomes. At this stage in the recipe, this step selects the origin, dest, and carrier variables. It also includes two new variables, date_dow and date_month, that were created by the earlier step_date(). More generally, the recipe selectors mean that you don’t always have to apply steps to individual variables one at a time. Since a recipe knows the variable type and role of each column, they can also be selected (or dropped) using this information. 15.1.3 Zero variance Note that since carrier and dest have some infrequently occurring values, it is possible that dummy variables might be created for values that don’t exist in the training set. For example, there could be destinations that are only in the test set. The function anti_join() returns all rows from x (test_data) where there are not matching values in y (train_data), keeping just columns from x.: test_data %&gt;% distinct(dest) %&gt;% anti_join(train_data) ## # A tibble: 1 x 1 ## dest ## &lt;fct&gt; ## 1 HDN When the recipe is applied to the training set, a column could contain only zeros. This is a “zero-variance predictor” that has no information within the column. While some R functions will not produce an error for such predictors, it usually causes warnings and other issues. step_zv() will remove columns from the data when the training set data have a single value, so it is added to the recipe after step_dummy(): flights_rec &lt;- recipe(arr_delay ~ ., data = train_data) %&gt;% update_role(flight, time_hour, new_role = &quot;ID&quot;) %&gt;% step_date(date, features = c(&quot;dow&quot;, &quot;month&quot;)) %&gt;% step_holiday(date, holidays = timeDate::listHolidays(&quot;US&quot;)) %&gt;% step_rm(date) %&gt;% step_dummy(all_nominal(), -all_outcomes()) %&gt;% step_zv(all_predictors()) 15.1.4 Correlations As a final step, we remove predictor variables that have large absolute correlations with other variables flights_rec &lt;- recipe(arr_delay ~ ., data = train_data) %&gt;% update_role(flight, time_hour, new_role = &quot;ID&quot;) %&gt;% step_date(date, features = c(&quot;dow&quot;, &quot;month&quot;)) %&gt;% step_holiday(date, holidays = timeDate::listHolidays(&quot;US&quot;)) %&gt;% step_rm(date) %&gt;% step_dummy(all_nominal(), -all_outcomes()) %&gt;% step_zv(all_predictors()) %&gt;% step_corr(all_predictors()) Now we’ve created a specification of what should be done with the data. "],["model-building-1.html", "Chapter 16 Model building 16.1 Logistic regression 16.2 Decision tree 16.3 Random forest 16.4 Boosted tree (XGBoost)", " Chapter 16 Model building Let’s use some classification algorithms to model the flight data. We start by building some models using the parsnip package: List of algorithms 16.1 Logistic regression lr_mod &lt;- logistic_reg() %&gt;% set_engine(&quot;glm&quot;) 16.2 Decision tree dt_mod &lt;- decision_tree() %&gt;% set_engine(&quot;C5.0&quot;) %&gt;% set_mode(&quot;classification&quot;) 16.3 Random forest rf_mod &lt;- rand_forest() %&gt;% set_engine(&quot;ranger&quot;) %&gt;% set_mode(&quot;classification&quot;) 16.4 Boosted tree (XGBoost) #install.packages(&quot;xgboost&quot;) xgb_mod &lt;- boost_tree() %&gt;% set_engine(&quot;xgboost&quot;) %&gt;% set_mode(&quot;classification&quot;) "],["recipe-and-models.html", "Chapter 17 Recipe and Models 17.1 Fit models with workflows 17.2 Train models 17.3 Model recipe objects 17.4 Summary", " Chapter 17 Recipe and Models We will want to use our recipe across several steps as we train and test our models. We will: Process the recipe using the training set: This involves any estimation or calculations based on the training set. For our recipe, the training set will be used to determine which predictors should be converted to dummy variables and which predictors will have zero-variance in the training set, and should be slated for removal. Apply the recipe to the training set: We create the final predictor set on the training set. Apply the recipe to the test set: We create the final predictor set on the test set. Nothing is recomputed and no information from the test set is used here; the dummy variable and zero-variance results from the training set are applied to the test set. To simplify this process, we can use a model workflow, which pairs a model and recipe together. This is a straightforward approach because different recipes are often needed for different models, so when a model and recipe are bundled, it becomes easier to train and test workflows. We’ll use the workflow package from tidymodels to bundle our parsnip model (lr_mod etc.) with our recipe (flights_rec). 17.1 Fit models with workflows To combine the data preparation with the model building, we use the package workflows. A workflow is an object that can bundle together your pre-processing, modeling, and post-processing requests. 17.1.1 Logistic regression flights_wflow_lr_mod &lt;- workflow() %&gt;% add_model(lr_mod) %&gt;% add_recipe(flights_rec) flights_wflow_lr_mod ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: logistic_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Logistic Regression Model Specification (classification) ## ## Computational engine: glm 17.1.2 Decision tree flights_wflow_dt_mod &lt;- workflow() %&gt;% add_model(dt_mod) %&gt;% add_recipe(flights_rec) flights_wflow_dt_mod ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: decision_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Decision Tree Model Specification (classification) ## ## Computational engine: C5.0 17.1.3 Random forest flights_wflow_rf_mod &lt;- workflow() %&gt;% add_model(rf_mod) %&gt;% add_recipe(flights_rec) flights_wflow_rf_mod ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: rand_forest() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Random Forest Model Specification (classification) ## ## Computational engine: ranger 17.1.4 XGBoost flights_wflow_xgb_mod &lt;- workflow() %&gt;% add_model(xgb_mod) %&gt;% add_recipe(flights_rec) flights_wflow_xgb_mod ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Boosted Tree Model Specification (classification) ## ## Computational engine: xgboost 17.2 Train models Now, there is a single function that can be used to prepare the recipe and train the models from the resulting predictors. 17.2.1 Logistic regression flights_fit_lr_mode &lt;- flights_wflow_lr_mod %&gt;% fit(data = train_data) flights_fit_lr_mode ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: logistic_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: stats::glm(formula = ..y ~ ., family = stats::binomial, data = data) ## ## Coefficients: ## (Intercept) dep_time ## 3.272e+01 -1.710e-03 ## air_time date_USChristmasDay ## -4.929e-02 -4.008e-01 ## date_USColumbusDay date_USCPulaskisBirthday ## 1.296e+01 9.247e-01 ## date_USDecorationMemorialDay date_USElectionDay ## 6.422e-02 1.121e+00 ## date_USGoodFriday date_USInaugurationDay ## 1.491e-01 4.502e-01 ## date_USIndependenceDay date_USLaborDay ## 1.082e+00 -1.792e+00 ## date_USLincolnsBirthday date_USMemorialDay ## -7.683e-01 1.125e+00 ## date_USMLKingsBirthday date_USNewYearsDay ## 4.219e-01 5.933e-01 ## date_USPresidentsDay date_USThanksgivingDay ## 4.346e-01 -5.125e-01 ## date_USVeteransDay date_USWashingtonsBirthday ## -3.183e-01 -5.277e-01 ## origin_JFK origin_LGA ## 3.618e-01 2.904e-02 ## dest_ACK dest_ALB ## -1.290e+01 -2.497e+01 ## dest_ATL dest_AUS ## -2.217e+01 -1.729e+01 ## dest_AVL dest_BDL ## -2.367e+01 -2.594e+01 ## dest_BGR dest_BHM ## -2.383e+01 -2.097e+01 ## dest_BNA dest_BOS ## -2.204e+01 -2.519e+01 ## dest_BQN dest_BTV ## -1.687e+01 -2.482e+01 ## dest_BUF dest_BUR ## -2.492e+01 -1.091e+01 ## dest_BWI dest_BZN ## -2.586e+01 -3.139e+00 ## dest_CAE dest_CAK ## -2.550e+01 -2.509e+01 ## dest_CHO dest_CHS ## -1.032e+01 -2.302e+01 ## dest_CLE dest_CLT ## -2.362e+01 -2.384e+01 ## dest_CMH dest_CRW ## -2.379e+01 -2.341e+01 ## ## ... ## and 106 more lines. 17.2.2 Decision tree flights_fit_dt_mode &lt;- flights_wflow_dt_mod %&gt;% fit(data = train_data) flights_fit_dt_mode ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: decision_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## C5.0.default(x = x, y = y, trials = 1, control = C50::C5.0Control(minCases = ## 2, sample = 0)) ## ## Classification Tree ## Number of samples: 7500 ## Number of predictors: 147 ## ## Tree size: 18 ## ## Non-standard options: attempt to group attributes 17.2.3 Random forest flights_fit_rf_mode &lt;- flights_wflow_rf_mod %&gt;% fit(data = train_data) flights_fit_rf_mode ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: rand_forest() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Ranger result ## ## Call: ## ranger::ranger(formula = ..y ~ ., data = data, num.threads = 1, verbose = FALSE, seed = sample.int(10^5, 1), probability = TRUE) ## ## Type: Probability estimation ## Number of trees: 500 ## Sample size: 7500 ## Number of independent variables: 147 ## Mtry: 12 ## Target node size: 10 ## Variable importance mode: none ## Splitrule: gini ## OOB prediction error (Brier s.): 0.1151285 17.2.4 XG Boost flights_fit_xgb_mode &lt;- flights_wflow_xgb_mod %&gt;% fit(data = train_data) flights_fit_xgb_mode ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## ● step_date() ## ● step_holiday() ## ● step_rm() ## ● step_dummy() ## ● step_zv() ## ● step_corr() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ##### xgb.Booster ## raw: 47.3 Kb ## call: ## xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, ## colsample_bytree = 1, min_child_weight = 1, subsample = 1), ## data = x, nrounds = 15, watchlist = wlist, verbose = 0, objective = &quot;binary:logistic&quot;, ## nthread = 1) ## params (as set within xgb.train): ## eta = &quot;0.3&quot;, max_depth = &quot;6&quot;, gamma = &quot;0&quot;, colsample_bytree = &quot;1&quot;, min_child_weight = &quot;1&quot;, subsample = &quot;1&quot;, objective = &quot;binary:logistic&quot;, nthread = &quot;1&quot;, validate_parameters = &quot;TRUE&quot; ## xgb.attributes: ## niter ## callbacks: ## cb.evaluation.log() ## # of features: 147 ## niter: 15 ## nfeatures : 147 ## evaluation_log: ## iter training_error ## 1 0.137333 ## 2 0.138533 ## --- ## 14 0.130400 ## 15 0.128267 17.3 Model recipe objects The objects above have the finalized recipe and fitted model objects inside. You may want to extract the model or recipe objects from the workflow. To do this, you can use the helper functions pull_workflow_fit() and pull_workflow_prepped_recipe(). For example, here we pull the fitted model object then use the broom::tidy() function to get a tidy tibble of the Logisitc Regression model coefficients. 17.3.1 Logistic regression flights_fit_lr_mode %&gt;% pull_workflow_fit() %&gt;% tidy() ## # A tibble: 148 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 32.7 702. 0.0466 9.63e- 1 ## 2 dep_time -0.00171 0.0000832 -20.5 8.07e-94 ## 3 air_time -0.0493 0.00337 -14.6 2.28e-48 ## 4 date_USChristmasDay -0.401 0.613 -0.654 5.13e- 1 ## 5 date_USColumbusDay 13.0 274. 0.0472 9.62e- 1 ## 6 date_USCPulaskisBirthday 0.925 0.765 1.21 2.27e- 1 ## 7 date_USDecorationMemorialDay 0.0642 0.579 0.111 9.12e- 1 ## 8 date_USElectionDay 1.12 1.07 1.05 2.95e- 1 ## 9 date_USGoodFriday 0.149 0.713 0.209 8.34e- 1 ## 10 date_USInaugurationDay 0.450 1.06 0.425 6.71e- 1 ## # … with 138 more rows 17.3.2 Decision tree flights_fit_xgb_mode %&gt;% pull_workflow_prepped_recipe() ## Data Recipe ## ## Inputs: ## ## role #variables ## ID 2 ## outcome 1 ## predictor 7 ## ## Training data contained 7500 data points and no missing data. ## ## Operations: ## ## Date features from date [trained] ## Holiday features from date [trained] ## Variables removed date [trained] ## Dummy variables from origin, dest, carrier, date_dow, date_month [trained] ## Zero variance filter removed dest_ANC, dest_EYW, dest_HDN, ... [trained] ## Correlation filter removed distance [trained] 17.3.3 Random forest flights_fit_rf_mode %&gt;% pull_workflow_prepped_recipe() ## Data Recipe ## ## Inputs: ## ## role #variables ## ID 2 ## outcome 1 ## predictor 7 ## ## Training data contained 7500 data points and no missing data. ## ## Operations: ## ## Date features from date [trained] ## Holiday features from date [trained] ## Variables removed date [trained] ## Dummy variables from origin, dest, carrier, date_dow, date_month [trained] ## Zero variance filter removed dest_ANC, dest_EYW, dest_HDN, ... [trained] ## Correlation filter removed distance [trained] 17.3.4 XG Boost flights_fit_xgb_mode %&gt;% pull_workflow_prepped_recipe() ## Data Recipe ## ## Inputs: ## ## role #variables ## ID 2 ## outcome 1 ## predictor 7 ## ## Training data contained 7500 data points and no missing data. ## ## Operations: ## ## Date features from date [trained] ## Holiday features from date [trained] ## Variables removed date [trained] ## Dummy variables from origin, dest, carrier, date_dow, date_month [trained] ## Zero variance filter removed dest_ANC, dest_EYW, dest_HDN, ... [trained] ## Correlation filter removed distance [trained] 17.4 Summary Our goal was to predict whether a plane arrives more than 30 minutes late. We have just: Built the model (lr_mod etc.), Created a preprocessing recipe (flights_rec), Bundled the model and recipe (flights_wflow), and Trained our workflow using a single call to fit(). The next step is to use the trained workflow (flights_fit) to predict with the unseen test data, which we will do with a single call to predict(). "],["prediction.html", "Chapter 18 Prediction 18.1 Logistic regression", " Chapter 18 Prediction The predict() method applies the recipe to the new data, then passes them to the fitted model. Let`s use the logistic regression model as an example for the next steps. 18.1 Logistic regression predict(flights_fit_lr_mode, test_data) ## # A tibble: 2,500 x 1 ## .pred_class ## &lt;fct&gt; ## 1 on_time ## 2 on_time ## 3 on_time ## 4 on_time ## 5 on_time ## 6 on_time ## 7 on_time ## 8 on_time ## 9 on_time ## 10 on_time ## # … with 2,490 more rows Because our outcome variable here is a factor, the output from predict() returns the predicted class: late versus on_time. But, let’s say we want the predicted class probabilities for each flight instead. To return those, we can specify type = \"prob\" when we use predict(). We’ll also bind the output with some variables from the test data and save them together: flights_pred_lr_mod &lt;- predict(flights_fit_lr_mode, test_data, type = &quot;prob&quot;) %&gt;% bind_cols(test_data %&gt;% select(arr_delay, time_hour, flight)) The data look like: head(flights_pred_lr_mod) ## # A tibble: 6 x 5 ## .pred_late .pred_on_time arr_delay time_hour flight ## &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dttm&gt; &lt;int&gt; ## 1 0.0358 0.964 on_time 2013-03-04 07:00:00 4122 ## 2 0.0987 0.901 on_time 2013-02-20 18:00:00 4517 ## 3 0.310 0.690 on_time 2013-04-02 18:00:00 373 ## 4 0.102 0.898 on_time 2013-12-10 06:00:00 4424 ## 5 0.0373 0.963 on_time 2013-10-30 10:00:00 2602 ## 6 0.0867 0.913 late 2013-05-25 08:00:00 3608 Now that we have a tibble with our predicted class probabilities, how will we evaluate the performance of our workflow? We would like to calculate a metric that tells how well our model predicted late arrivals, compared to the true status of our outcome variable, arr_delay. 18.1.1 ROC curve Let’s use the area under the ROC curve as our metric, computed using roc_curve() and roc_auc() from the yardstick package. To generate a ROC curve, we need the predicted class probabilities for late and on_time, which we just calculated in the code chunk above. We can create the ROC curve with these values, using roc_curve() and then piping to the autoplot() method: flights_pred_lr_mod %&gt;% roc_curve(truth = arr_delay, .pred_late) %&gt;% autoplot() 18.1.2 AUC Similarly, roc_auc() estimates the area under the curve: flights_pred_lr_mod %&gt;% roc_auc(truth = arr_delay, .pred_late) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 roc_auc binary 0.746 18.1.3 Accuracy We use the metrics() function to measure the performance of the model. It will automatically choose metrics appropriate for a given type of model. The function expects a tibble that contains the actual results (truth) and what the model predicted (estimate). flights_fit_lr_mode %&gt;% predict(test_data) %&gt;% bind_cols(test_data) %&gt;% metrics(truth = arr_delay, estimate = .pred_class) ## # A tibble: 2 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.847 ## 2 kap binary 0.182 18.1.4 Recall flights_fit_lr_mode %&gt;% predict(test_data) %&gt;% bind_cols(test_data) %&gt;% recall(truth = arr_delay, estimate = .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 recall binary 0.153 18.1.5 Precision flights_fit_lr_mode %&gt;% predict(test_data) %&gt;% bind_cols(test_data) %&gt;% precision(truth = arr_delay, estimate = .pred_class) ## # A tibble: 1 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 precision binary 0.541 "],["references.html", "References", " References "]]
